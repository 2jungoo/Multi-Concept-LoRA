# ğŸ¨ Multi-LoRA Style Transfer for Stable Diffusion

Stable Diffusion 1.5ì— ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ LoRAë¥¼ í•™ìŠµí•˜ì—¬ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì„ ì œì–´í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

- 4ê°€ì§€ ìŠ¤íƒ€ì¼ LoRA í•™ìŠµ (Watercolor, Cartoon, Anime, Pixelart)
- Multi-LoRA ì¡°í•©ì„ í†µí•œ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ìƒì„±
- ë°ì´í„°ì…‹ í•´ìƒë„ì— ë”°ë¥¸ í•™ìŠµ í’ˆì§ˆ ë¶„ì„ (Ablation Study)

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼

### ìŠ¤íƒ€ì¼ë³„ ìƒì„± ê²°ê³¼

| Base Model | Watercolor | Cartoon | Anime | Pixelart |
|:----------:|:----------:|:-------:|:-----:|:--------:|
| ![base](results/base.png) | ![wc](results/watercolor.png) | ![ct](results/cartoon.png) | ![an](results/anime.png) | ![px](results/pixelart.png) |

### ë°ì´í„°ì…‹ í•´ìƒë„ vs í•™ìŠµ í’ˆì§ˆ (Ablation Study)

| Dataset | ì›ë³¸ í•´ìƒë„ | ì´ë¯¸ì§€ ìˆ˜ | Best Loss | ê²°ê³¼ í’ˆì§ˆ |
|---------|------------|----------|-----------|----------|
| Cartoon | ~2000Ã—2000 | 61 | 0.1194 | âœ… ìš°ìˆ˜ |
| Watercolor | 416Ã—416 | 100 | 0.0871 | âœ… ì–‘í˜¸ |
| Anime | 61~94Ã—61~94 | 100 | 0.0871 | âš ï¸ ë³´í†µ |
| **Pixelart** | **16Ã—16** | 100 | 0.0221 | âŒ ì‹¤íŒ¨ |

> **ê²°ë¡ **: LoRA í•™ìŠµì—ëŠ” ìµœì†Œ 256Ã—256 ì´ìƒì˜ í•´ìƒë„ ê¶Œì¥. ê·¹ì €í•´ìƒë„(16Ã—16) ì´ë¯¸ì§€ëŠ” ì—…ìŠ¤ì¼€ì¼í•´ë„ ì •ë³´ ì†ì‹¤ë¡œ ì˜ë¯¸ ìˆëŠ” ìŠ¤íƒ€ì¼ í•™ìŠµ ë¶ˆê°€

### CLIP Score ë¹„êµ

| Model | CLIP Score | ë¹„ê³  |
|-------|------------|------|
| Base (SD 1.5) | 0.310 | ê¸°ì¤€ |
| Watercolor | 0.299 | ìŠ¤íƒ€ì¼ ì ìš©ë¨ |
| Cartoon | 0.286 | ìŠ¤íƒ€ì¼ ì ìš©ë¨ |
| Multi-LoRA | 0.292 | ì¡°í•© íš¨ê³¼ |

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Base Model**: Stable Diffusion v1.5
- **Fine-tuning**: LoRA (Low-Rank Adaptation) with PEFT
- **Framework**: PyTorch 2.2.0, Diffusers 0.27.0
- **Hardware**: NVIDIA H100 80GB
- **Evaluation**: CLIP Score, FID

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°
```
â”œâ”€â”€ main.py                 # CLI ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt        # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_data.py  # ë°ì´í„° ì „ì²˜ë¦¬ + BLIP ìº¡ì…”ë‹
â”‚   â”œâ”€â”€ train_lora.py       # LoRA í•™ìŠµ
â”‚   â”œâ”€â”€ inference.py        # Multi-LoRA ì¶”ë¡ 
â”‚   â””â”€â”€ evaluate.py         # CLIP/FID í‰ê°€
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ lora_base_config.toml
â”œâ”€â”€ data/                   # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ (Git ì œì™¸)
â”œâ”€â”€ output/                 # í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ (Git ì œì™¸)
â””â”€â”€ evaluation/             # í‰ê°€ ê²°ê³¼
```

## ğŸš€ ì‚¬ìš©ë²•

### 1. í™˜ê²½ ì„¤ì •
```bash
# Conda í™˜ê²½ ìƒì„±
conda create -n lora_env python=3.10 -y
conda activate lora_env

# PyTorch ì„¤ì¹˜ (CUDA 12.1)
pip install torch==2.2.0 torchvision==0.17.0 --index-url https://download.pytorch.org/whl/cu121

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ë°ì´í„° ì „ì²˜ë¦¬
```bash
python main.py preprocess \
    --watercolor_dir /path/to/watercolor \
    --cartoon_dir /path/to/cartoon
```

### 3. LoRA í•™ìŠµ
```bash
python main.py train --epochs 20 --batch_size 1 --learning_rate 1e-4
```

### 4. ì´ë¯¸ì§€ ìƒì„±
```bash
python main.py inference
```

### 5. í‰ê°€
```bash
python main.py evaluate
```

## ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­

### 1. ë°ì´í„° í•´ìƒë„ì˜ ì¤‘ìš”ì„±
- ê³ í•´ìƒë„(400px+): ìŠ¤íƒ€ì¼ íŠ¹ì§•ì„ ì˜ í•™ìŠµ
- ì €í•´ìƒë„(100px-): ì—…ìŠ¤ì¼€ì¼í•´ë„ ì •ë³´ ì†ì‹¤
- ê·¹ì €í•´ìƒë„(16px): í•™ìŠµ ìì²´ê°€ ë¬´ì˜ë¯¸

### 2. Multi-LoRA ì¡°í•©
- ì„œë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ì˜ LoRAë¥¼ ê°€ì¤‘ì¹˜ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ìƒì„± ê°€ëŠ¥
- ì˜ˆ: `watercolor(0.6) + cartoon(0.4)` = ìˆ˜ì±„í™” ëŠë‚Œì˜ ë§Œí™”í’

### 3. í•™ìŠµ ì•ˆì •ì„±
- `mixed_precision="no"` (fp32) ì‚¬ìš© ì‹œ NaN loss ë°©ì§€
- Learning rate 1e-4ê°€ ì•ˆì •ì 

## ğŸ“š ì°¸ê³  ìë£Œ

- [Stable Diffusion v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
- [PEFT LoRA Documentation](https://huggingface.co/docs/peft/conceptual_guides/lora)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

---

**AIì‘ìš©í•™ê³¼ 2191192 ì´ì¤€êµ¬** | ì‹œê°ì§€ëŠ¥í•™ìŠµ[A] ê¸°ë§ í”„ë¡œì íŠ¸
